{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10987825,"sourceType":"datasetVersion","datasetId":6838858},{"sourceId":10998928,"sourceType":"datasetVersion","datasetId":6846899}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:31:28.128684Z","iopub.execute_input":"2025-03-11T21:31:28.128919Z","iopub.status.idle":"2025-03-11T21:31:31.292383Z","shell.execute_reply.started":"2025-03-11T21:31:28.128901Z","shell.execute_reply":"2025-03-11T21:31:31.291742Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ntest_df = pd.read_csv(\"/kaggle/input/mnist-cv-test/mnist_test.csv\")\n\ntrain_df = pd.read_csv(\"/kaggle/input/mnist-cv-test/mnist_train.csv\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:31:31.293613Z","iopub.execute_input":"2025-03-11T21:31:31.293950Z","iopub.status.idle":"2025-03-11T21:31:34.169566Z","shell.execute_reply.started":"2025-03-11T21:31:31.293932Z","shell.execute_reply":"2025-03-11T21:31:34.168839Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Function to plot sample images\nfrom tqdm import tqdm\n\ndef to_image(df):\n\n    new_df = pd.DataFrame()\n    images = []\n    labels = []\n    for i in tqdm(range(len(df))):\n        # Reshape the flattened image to 28x28\n        \n        image = df.iloc[i, 1:].values.reshape(28, 28) #resize\n        image = image/255.0 # Normalize\n        \n        label = df.iloc[i, 0]\n        \n        images.append(image)\n        labels.append(label)\n        \n    new_df['images'] = images\n    new_df['labels'] = labels\n\n    return new_df\n# Plot sample images from the training data\nnew_train_df = to_image(train_df)\nnew_test_df = to_image(test_df)\n\n# Plot sample images from the testing data\n\n# new_test_path = \"/kaggle/working/test_images.csv\"\n# new_train_path = \"/kaggle/working/train_images.csv\"\n\n# new_train_df.to_csv(new_train_path)\n# new_test_df.to_csv(new_test_path)\n\n# print(f\"images saved to {new_train_path} and {new_test_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:31:34.170558Z","iopub.execute_input":"2025-03-11T21:31:34.170902Z","iopub.status.idle":"2025-03-11T21:31:41.217142Z","shell.execute_reply.started":"2025-03-11T21:31:34.170878Z","shell.execute_reply":"2025-03-11T21:31:41.216313Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 59999/59999 [00:05<00:00, 10286.36it/s]\n100%|██████████| 9999/9999 [00:01<00:00, 9346.22it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## dataset split\nX_train = new_train_df['images'].values\ny_train = new_train_df['labels']\n\ntest_images = new_test_df['images'].values\ntest_labels = new_test_df['labels']\n\ny_train = torch.tensor(y_train, dtype=torch.long)\ntest_labels = torch.tensor(test_labels, dtype=torch.long)\n\n# One-hot encode the labels\nnum_classes = 10  # Number of classes (0 to 9)\ny_train = torch.nn.functional.one_hot(y_train, num_classes=num_classes)\ntest_labels = torch.nn.functional.one_hot(test_labels, num_classes=num_classes)\n\n\nX_test = test_images[:len(test_images)//2]\nX_val = test_images[len(test_images)//2:]\n\ny_test = test_labels[:len(test_labels)//2]\ny_val = test_labels[len(test_labels)//2:]\n\n\n\nlen(X_train),len(y_train),len(X_test),len(X_val ),len(y_test),len(y_val )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:32:29.425989Z","iopub.execute_input":"2025-03-11T21:32:29.426303Z","iopub.status.idle":"2025-03-11T21:32:29.468097Z","shell.execute_reply.started":"2025-03-11T21:32:29.426280Z","shell.execute_reply":"2025-03-11T21:32:29.467346Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(59999, 59999, 4999, 5000, 4999, 5000)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nfor i in tqdm(range(len(X_train))):\n    X_train[i] = list(X_train[i])\nX_train = list(X_train)\nX_train = np.array(X_train, dtype=np.float32)  \nX_train = torch.tensor(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:32:47.919580Z","iopub.execute_input":"2025-03-11T21:32:47.920045Z","iopub.status.idle":"2025-03-11T21:32:48.786105Z","shell.execute_reply.started":"2025-03-11T21:32:47.920001Z","shell.execute_reply":"2025-03-11T21:32:48.785412Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 59999/59999 [00:00<00:00, 1101369.18it/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"X_train = X_train.unsqueeze(1)\nX_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:32:50.221818Z","iopub.execute_input":"2025-03-11T21:32:50.222283Z","iopub.status.idle":"2025-03-11T21:32:50.227445Z","shell.execute_reply.started":"2025-03-11T21:32:50.222250Z","shell.execute_reply":"2025-03-11T21:32:50.226764Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([59999, 1, 28, 28])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in tqdm(range(len(X_test))):\n    X_test[i] = list(X_test[i])\nX_test = list(X_test)\nX_test = np.array(X_test, dtype=np.float32)  \nX_test = torch.tensor(X_test)\nX_test = X_test.unsqueeze(1)\n\n\nfor i in tqdm(range(len(X_val))):\n    X_val[i] = list(X_val[i])\nX_val = list(X_val)\nX_val = np.array(X_val, dtype=np.float32)  \nX_val = torch.tensor(X_val)\nX_val = X_val.unsqueeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:32:53.375619Z","iopub.execute_input":"2025-03-11T21:32:53.375980Z","iopub.status.idle":"2025-03-11T21:32:53.525340Z","shell.execute_reply.started":"2025-03-11T21:32:53.375954Z","shell.execute_reply":"2025-03-11T21:32:53.524508Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 4999/4999 [00:00<00:00, 933332.99it/s]\n100%|██████████| 5000/5000 [00:00<00:00, 1101734.70it/s]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"y_train = torch.tensor(y_train)\n# y_train = y_train.unsqueeze(1)\ny_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:32:55.518428Z","iopub.execute_input":"2025-03-11T21:32:55.518765Z","iopub.status.idle":"2025-03-11T21:32:55.525155Z","shell.execute_reply.started":"2025-03-11T21:32:55.518736Z","shell.execute_reply":"2025-03-11T21:32:55.524130Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-17-aa5db8dc8cc2>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_train = torch.tensor(y_train)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"torch.Size([59999, 10])"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"y_test = torch.tensor(y_test)\n# y_test = y_test.unsqueeze(1)\n\ny_val = torch.tensor(y_val) \n# y_val = y_val.unsqueeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:33:14.854987Z","iopub.execute_input":"2025-03-11T21:33:14.855276Z","iopub.status.idle":"2025-03-11T21:33:14.860043Z","shell.execute_reply.started":"2025-03-11T21:33:14.855252Z","shell.execute_reply":"2025-03-11T21:33:14.859342Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-19-7d64a92bd736>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_test = torch.tensor(y_test)\n<ipython-input-19-7d64a92bd736>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y_val = torch.tensor(y_val)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass MnistDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.labels[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:33:17.684988Z","iopub.execute_input":"2025-03-11T21:33:17.685332Z","iopub.status.idle":"2025-03-11T21:33:17.690114Z","shell.execute_reply.started":"2025-03-11T21:33:17.685305Z","shell.execute_reply":"2025-03-11T21:33:17.689188Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\nbatch_size = 32\n\ntrain_dataset = MnistDataset(X_train, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\ntest_dataset = MnistDataset(X_test, y_test)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n\n\nval_dataset = MnistDataset(X_val, y_val)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:33:17.843927Z","iopub.execute_input":"2025-03-11T21:33:17.844344Z","iopub.status.idle":"2025-03-11T21:33:17.850592Z","shell.execute_reply.started":"2025-03-11T21:33:17.844308Z","shell.execute_reply":"2025-03-11T21:33:17.849676Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:33:20.340814Z","iopub.execute_input":"2025-03-11T21:33:20.341225Z","iopub.status.idle":"2025-03-11T21:33:20.345676Z","shell.execute_reply.started":"2025-03-11T21:33:20.341192Z","shell.execute_reply":"2025-03-11T21:33:20.344726Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Block_1(nn.Module):\n    def __init__(self):\n        super(Block_1, self).__init__()\n        self.relu = nn.ReLU()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm1 = nn.BatchNorm2d(64)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))  # Reduced kernel size and stride\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.batchnorm1(x)\n        x = self.relu(x)\n        op1 = self.maxpool1(x)\n        return op1\n\n\nclass Block_2_1(nn.Module):\n    def __init__(self):\n        super(Block_2_1, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout_percentage = 0.5\n\n        self.conv2_1_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm2_1_1 = nn.BatchNorm2d(64)\n        self.conv2_1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm2_1_2 = nn.BatchNorm2d(64)\n        self.dropout2_1 = nn.Dropout(p=self.dropout_percentage)\n\n    def forward(self, op1):\n        x = self.conv2_1_1(op1)\n        x = self.batchnorm2_1_1(x)\n        x = self.relu(x)\n        x = self.conv2_1_2(x)\n        x = self.batchnorm2_1_2(x)\n        x = self.dropout2_1(x)\n        op2_1 = self.relu(x + op1)\n        return op2_1\n\n\nclass Block_2_2(nn.Module):\n    def __init__(self):\n        super(Block_2_2, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout_percentage = 0.5\n\n        self.conv2_2_1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm2_2_1 = nn.BatchNorm2d(64)\n        self.conv2_2_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm2_2_2 = nn.BatchNorm2d(64)\n        self.dropout2_2 = nn.Dropout(p=self.dropout_percentage)\n\n    def forward(self, op2_1):\n        x = self.conv2_2_1(op2_1)\n        x = self.batchnorm2_2_1(x)\n        x = self.relu(x)\n        x = self.conv2_2_2(x)\n        x = self.batchnorm2_2_2(x)\n        x = self.dropout2_2(x)\n        op2 = self.relu(x + op2_1)\n        return op2\n\n\nclass Block_3(nn.Module):\n    def __init__(self):\n        super(Block_3, self).__init__()\n        self.relu = nn.ReLU()\n        self.dropout_percentage = 0.5\n\n        self.conv3_1_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        self.batchnorm3_1_1 = nn.BatchNorm2d(128)\n        self.conv3_1_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm3_1_2 = nn.BatchNorm2d(128)\n\n        # Skip connection\n        self.concat_adjust_3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(1, 1), stride=(2, 2), padding=(0, 0))\n        self.dropout3_1 = nn.Dropout(p=self.dropout_percentage)\n\n        self.conv3_2_1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm3_2_1 = nn.BatchNorm2d(128)\n        self.conv3_2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        self.batchnorm3_2_2 = nn.BatchNorm2d(128)\n        self.dropout3_2 = nn.Dropout(p=self.dropout_percentage)\n\n    def forward(self, op2):\n        x = self.conv3_1_1(op2)\n        x = self.batchnorm3_1_1(x)\n        x = self.relu(x)\n        x = self.conv3_1_2(x)\n        x = self.batchnorm3_1_2(x)\n        x = self.dropout3_1(x)\n\n        op2 = self.concat_adjust_3(op2)  # Skip connection\n        op3_1 = self.relu(x + op2)\n\n        x = self.conv3_2_1(op3_1)\n        x = self.batchnorm3_2_1(x)\n        x = self.relu(x)\n        x = self.conv3_2_2(x)\n        x = self.batchnorm3_2_2(x)\n        x = self.dropout3_2(x)\n        op3 = self.relu(x + op3_1)\n\n        return op3\n\n\nclass Resnet18(nn.Module):\n    def __init__(self, n_classes):\n        super(Resnet18, self).__init__()\n\n        self.block1 = Block_1()\n        self.block2_1 = Block_2_1()\n        self.block2_2 = Block_2_2()\n        self.block3 = Block_3()\n\n        # Final block\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Dynamically adjust pooling size\n        self.fc = nn.Linear(in_features=128, out_features=1000)\n        self.out = nn.Linear(in_features=1000, out_features=n_classes)\n\n    def forward(self, x):\n        op1 = self.block1(x)\n        op2_1 = self.block2_1(op1)\n        op2 = self.block2_2(op2_1)\n        op3 = self.block3(op2)\n\n        x = self.avgpool(op3)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n        x = self.out(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:33:20.600984Z","iopub.execute_input":"2025-03-11T21:33:20.601304Z","iopub.status.idle":"2025-03-11T21:33:20.697169Z","shell.execute_reply.started":"2025-03-11T21:33:20.601280Z","shell.execute_reply":"2025-03-11T21:33:20.696144Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n\nimport torch.optim as optim\n\n\n\nclass EarlyStopping:\n    def __init__(self, patience=5, min_delta=0):\n        \n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n\noutput_size = 10\nlearning_rate = 0.001\nbatch_size = 32\nnum_epochs = 2 #10\nn_classes = 10\n# Instantiate the model, loss function, and optimizer\nmodel = Resnet18(n_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\nearly_stopping = EarlyStopping(patience=5, min_delta=0.01)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:59:35.842216Z","iopub.execute_input":"2025-03-11T21:59:35.842494Z","iopub.status.idle":"2025-03-11T21:59:35.860115Z","shell.execute_reply.started":"2025-03-11T21:59:35.842474Z","shell.execute_reply":"2025-03-11T21:59:35.859409Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"\n\n\ndef calculate_accuracy(loader, model):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in tqdm(loader , desc = \"Processing accuracy...\" ):\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n\n            # If labels are one-hot encoded, convert them to class indices\n            if labels.dim() > 1 and labels.size(1) > 1:  # Check if labels are one-hot encoded\n                labels = torch.argmax(labels, dim=1)  # Convert to class indices\n\n            # Compare predicted and true class indices\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n            # print(correct / total)\n\n    \n    return 100 * correct / total\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:54:36.977415Z","iopub.execute_input":"2025-03-11T21:54:36.977749Z","iopub.status.idle":"2025-03-11T21:54:36.983478Z","shell.execute_reply.started":"2025-03-11T21:54:36.977722Z","shell.execute_reply":"2025-03-11T21:54:36.982530Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n\n    for i, (inputs, labels) in tqdm(enumerate(train_loader) , desc = \"training over Batches\"):\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        outputs = outputs.squeeze(1)\n\n        # labels = labels.long()\n        labels = labels.float()\n\n        try:\n        # print(outputs.shape,labels.shape)\n            loss = criterion(outputs, labels)\n        except Exception as e:\n            print(e)\n            continue\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n        if (i + 1) % 100 == 0:\n            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n\n\n    \n    \n    model.eval()\n    test_loss = 0.0\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader , desc = \"calculating test loss over an epoch..\"):\n            outputs = model(inputs)\n            outputs = outputs.squeeze(1)\n\n\n            labels = labels.float()\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n    \n    # Calculate Loss\n\n    \n    \n    train_loss /= len(train_loader)\n    test_loss /= len(test_loader)\n\n\n    \n    # Calculate accuracy\n    train_acc = calculate_accuracy(train_loader, model)\n    test_acc = calculate_accuracy(test_loader, model)\n\n\n    \n\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {test_loss:.4f} '\n          f'Train Accuracy: {train_acc:.2f}%, Test Accuracy: {test_acc:.2f}%')\n\n\n    scheduler.step(test_loss)\n\n    early_stopping(test_loss)\n    if early_stopping.early_stop:\n        print(\"Early stopping triggered!\")\n        break\nprint('Training complete.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:59:38.828520Z","iopub.execute_input":"2025-03-11T21:59:38.828891Z","iopub.status.idle":"2025-03-11T22:07:45.680716Z","shell.execute_reply.started":"2025-03-11T21:59:38.828862Z","shell.execute_reply":"2025-03-11T22:07:45.679794Z"}},"outputs":[{"name":"stderr","text":"training over Batches: 102it [00:09, 10.73it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [100/1875], Loss: 0.2287\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 202it [00:18, 10.79it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [200/1875], Loss: 0.0714\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 302it [00:29,  9.82it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [300/1875], Loss: 0.2092\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 402it [00:38, 10.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [400/1875], Loss: 0.3134\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 502it [00:47, 10.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [500/1875], Loss: 0.2599\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 602it [00:57, 10.61it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [600/1875], Loss: 0.0121\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 702it [01:07, 10.87it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [700/1875], Loss: 0.3756\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 802it [01:16, 10.63it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [800/1875], Loss: 0.2751\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 902it [01:26, 10.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [900/1875], Loss: 0.0184\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1002it [01:36, 10.73it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1000/1875], Loss: 0.0815\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1102it [01:45, 10.69it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1100/1875], Loss: 0.0260\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1202it [01:55, 10.79it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1200/1875], Loss: 0.0012\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1301it [02:04,  6.77it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1300/1875], Loss: 0.2780\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1402it [02:14, 10.67it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1400/1875], Loss: 0.2855\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1502it [02:24, 10.54it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1500/1875], Loss: 0.0229\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1602it [02:33, 10.58it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1600/1875], Loss: 0.0082\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1702it [02:43, 10.86it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1700/1875], Loss: 0.0183\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1802it [02:52, 10.72it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Step [1800/1875], Loss: 0.0549\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1875it [02:59, 10.45it/s]\ncalculating test loss over an epoch..: 100%|██████████| 157/157 [00:04<00:00, 35.72it/s]\nProcessing accuracy...: 100%|██████████| 1875/1875 [00:54<00:00, 34.16it/s]\nProcessing accuracy...: 100%|██████████| 157/157 [00:04<00:00, 35.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/2], Train Loss: 0.1792, Val Loss: 0.1169 Train Accuracy: 97.15%, Test Accuracy: 96.28%\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 101it [00:10,  7.26it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [100/1875], Loss: 0.0316\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 202it [00:19, 10.57it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [200/1875], Loss: 0.0260\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 302it [00:29, 10.85it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [300/1875], Loss: 0.0017\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 402it [00:38, 10.75it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [400/1875], Loss: 0.1782\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 501it [00:48, 10.57it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [500/1875], Loss: 0.0362\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 601it [00:57, 10.12it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [600/1875], Loss: 0.0123\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 701it [01:06, 10.80it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [700/1875], Loss: 0.0114\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 801it [01:16, 10.75it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [800/1875], Loss: 0.7097\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 901it [01:26, 10.62it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [900/1875], Loss: 0.0891\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1001it [01:35, 10.76it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1000/1875], Loss: 0.0059\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1101it [01:45,  6.79it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1100/1875], Loss: 0.1067\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1202it [01:55, 10.75it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1200/1875], Loss: 0.1148\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1302it [02:04, 10.66it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1300/1875], Loss: 0.0155\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1402it [02:14, 10.59it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1400/1875], Loss: 0.3396\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1501it [02:24, 10.74it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1500/1875], Loss: 0.0174\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1601it [02:33, 10.71it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1600/1875], Loss: 0.1103\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1701it [02:43, 10.70it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1700/1875], Loss: 0.0613\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1802it [02:53, 10.55it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Step [1800/1875], Loss: 0.0214\n","output_type":"stream"},{"name":"stderr","text":"training over Batches: 1875it [03:00, 10.40it/s]\ncalculating test loss over an epoch..: 100%|██████████| 157/157 [00:04<00:00, 35.36it/s]\nProcessing accuracy...: 100%|██████████| 1875/1875 [00:54<00:00, 34.43it/s]\nProcessing accuracy...: 100%|██████████| 157/157 [00:04<00:00, 35.38it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/2], Train Loss: 0.0749, Val Loss: 0.0487 Train Accuracy: 98.83%, Test Accuracy: 98.42%\nTraining complete.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"\n\n\n\n\ndef calculate_accuracy(loader, model):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in tqdm(loader , desc = \"Processing accuracy...\" ):\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n\n            # If labels are one-hot encoded, convert them to class indices\n            if labels.dim() > 1 and labels.size(1) > 1:  # Check if labels are one-hot encoded\n                labels = torch.argmax(labels, dim=1)  # Convert to class indices\n\n            # Compare predicted and true class indices\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n            # print(correct / total)\n\n    \n    return 100 * correct / total\n\n\n\ntrain_acc = calculate_accuracy(train_loader, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:53:25.382406Z","iopub.execute_input":"2025-03-11T21:53:25.382711Z","iopub.status.idle":"2025-03-11T21:54:20.380496Z","shell.execute_reply.started":"2025-03-11T21:53:25.382686Z","shell.execute_reply":"2025-03-11T21:54:20.379615Z"}},"outputs":[{"name":"stderr","text":"Processing accuracy...: 100%|██████████| 1875/1875 [00:54<00:00, 34.10it/s]\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"train_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:53:23.589214Z","iopub.execute_input":"2025-03-11T21:53:23.589560Z","iopub.status.idle":"2025-03-11T21:53:23.594407Z","shell.execute_reply.started":"2025-03-11T21:53:23.589534Z","shell.execute_reply":"2025-03-11T21:53:23.593718Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"98.35163919398657"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T21:44:31.467584Z","iopub.execute_input":"2025-03-11T21:44:31.467949Z","iopub.status.idle":"2025-03-11T21:44:31.480427Z","shell.execute_reply.started":"2025-03-11T21:44:31.467910Z","shell.execute_reply":"2025-03-11T21:44:31.479280Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-f5f7acea0338>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'total' is not defined"],"ename":"NameError","evalue":"name 'total' is not defined","output_type":"error"}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import precision_score, recall_score\nimport numpy as np\n\ndef calculate_metrics(loader, model):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in loader:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n            \n            if labels.dim() > 1 and labels.size(1) > 1:  # Check if labels are one-hot encoded\n                labels = torch.argmax(labels, dim=1)\n\n            \n            all_preds.extend(predicted.cpu().numpy())\n            \n            all_labels.extend(labels.cpu().numpy())\n\n    # Convert lists to numpy arrays\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n\n    # Calculate accuracy\n    accuracy = 100 * (all_preds == all_labels).sum() / len(all_labels)\n\n    # Calculate precision and recall\n    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n\n    return accuracy, precision, recall\n\naccuracy, precision, recall = calculate_metrics(val_loader, model)\n\n# Print results\nprint(f\"Accuracy: {accuracy:.2f}%\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:08:00.250480Z","iopub.execute_input":"2025-03-11T22:08:00.250796Z","iopub.status.idle":"2025-03-11T22:08:05.176644Z","shell.execute_reply.started":"2025-03-11T22:08:00.250772Z","shell.execute_reply":"2025-03-11T22:08:05.175797Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 99.30%\nPrecision: 0.9931\nRecall: 0.9929\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.onnx\n\n\n# Instantiate the model\nmodel = Resnet18(n_classes = 10)\n\n# Set the model to evaluation mode\nmodel.eval()\n\ndummy_input = train_dataset[1][0].unsqueeze(0)  # Example: batch size of 1, 32 channels, 28x28 image\n\n# Define the output ONNX file path\nonnx_file_path = \"/kaggle/working/resnet18_v1.onnx\"\n\n# Export the model to ONNX\ntorch.onnx.export(\n    model,                  # Model to export\n    dummy_input,            # Dummy input to the model\n    onnx_file_path,         # Output ONNX file path\n    export_params=True,     # Store the trained parameter weights inside the model file\n    opset_version=11,       # ONNX opset version to use\n    do_constant_folding=True,  # Optimize the model by folding constants\n    input_names=['input'],  # Name of the input node\n    output_names=['output'],  # Name of the output node\n    dynamic_axes={          # Dynamic axes for variable batch size\n        'input': {0: 'batch_size'},\n        'output': {0: 'batch_size'},\n    }\n)\n\nprint(f\"Model exported to {onnx_file_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:11:45.431562Z","iopub.execute_input":"2025-03-11T22:11:45.431885Z","iopub.status.idle":"2025-03-11T22:11:45.753918Z","shell.execute_reply.started":"2025-03-11T22:11:45.431860Z","shell.execute_reply":"2025-03-11T22:11:45.752984Z"}},"outputs":[{"name":"stdout","text":"Model exported to /kaggle/working/resnet18_v1.onnx\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import onnx\n\n# Load the ONNX model\nonnx_model = onnx.load(\"/kaggle/working/resnet18_v1.onnx\")\n\n# Check that the model is well-formed\nonnx.checker.check_model(onnx_model)\n\n# Print a human-readable representation of the model\nprint(onnx.helper.printable_graph(onnx_model.graph))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:13:56.528825Z","iopub.execute_input":"2025-03-11T22:13:56.529124Z","iopub.status.idle":"2025-03-11T22:13:56.562440Z","shell.execute_reply.started":"2025-03-11T22:13:56.529100Z","shell.execute_reply":"2025-03-11T22:13:56.561696Z"}},"outputs":[{"name":"stdout","text":"graph main_graph (\n  %input[FLOAT, batch_sizex1x28x28]\n) initializers (\n  %block3.concat_adjust_3.weight[FLOAT, 128x64x1x1]\n  %block3.concat_adjust_3.bias[FLOAT, 128]\n  %fc.weight[FLOAT, 1000x128]\n  %fc.bias[FLOAT, 1000]\n  %out.weight[FLOAT, 10x1000]\n  %out.bias[FLOAT, 10]\n  %onnx::Conv_115[FLOAT, 64x1x3x3]\n  %onnx::Conv_116[FLOAT, 64]\n  %onnx::Conv_118[FLOAT, 64x64x3x3]\n  %onnx::Conv_119[FLOAT, 64]\n  %onnx::Conv_121[FLOAT, 64x64x3x3]\n  %onnx::Conv_122[FLOAT, 64]\n  %onnx::Conv_124[FLOAT, 64x64x3x3]\n  %onnx::Conv_125[FLOAT, 64]\n  %onnx::Conv_127[FLOAT, 64x64x3x3]\n  %onnx::Conv_128[FLOAT, 64]\n  %onnx::Conv_130[FLOAT, 128x64x3x3]\n  %onnx::Conv_131[FLOAT, 128]\n  %onnx::Conv_133[FLOAT, 128x128x3x3]\n  %onnx::Conv_134[FLOAT, 128]\n  %onnx::Conv_136[FLOAT, 128x128x3x3]\n  %onnx::Conv_137[FLOAT, 128]\n  %onnx::Conv_139[FLOAT, 128x128x3x3]\n  %onnx::Conv_140[FLOAT, 128]\n) {\n  %/block1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input, %onnx::Conv_115, %onnx::Conv_116)\n  %/block1/relu/Relu_output_0 = Relu(%/block1/conv1/Conv_output_0)\n  %/block1/maxpool1/MaxPool_output_0 = MaxPool[ceil_mode = 0, dilations = [1, 1], kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%/block1/relu/Relu_output_0)\n  %/block2_1/conv2_1_1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block1/maxpool1/MaxPool_output_0, %onnx::Conv_118, %onnx::Conv_119)\n  %/block2_1/relu/Relu_output_0 = Relu(%/block2_1/conv2_1_1/Conv_output_0)\n  %/block2_1/conv2_1_2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block2_1/relu/Relu_output_0, %onnx::Conv_121, %onnx::Conv_122)\n  %/block2_1/Add_output_0 = Add(%/block2_1/conv2_1_2/Conv_output_0, %/block1/maxpool1/MaxPool_output_0)\n  %/block2_1/relu_1/Relu_output_0 = Relu(%/block2_1/Add_output_0)\n  %/block2_2/conv2_2_1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block2_1/relu_1/Relu_output_0, %onnx::Conv_124, %onnx::Conv_125)\n  %/block2_2/relu/Relu_output_0 = Relu(%/block2_2/conv2_2_1/Conv_output_0)\n  %/block2_2/conv2_2_2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block2_2/relu/Relu_output_0, %onnx::Conv_127, %onnx::Conv_128)\n  %/block2_2/Add_output_0 = Add(%/block2_2/conv2_2_2/Conv_output_0, %/block2_1/relu_1/Relu_output_0)\n  %/block2_2/relu_1/Relu_output_0 = Relu(%/block2_2/Add_output_0)\n  %/block3/conv3_1_1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/block2_2/relu_1/Relu_output_0, %onnx::Conv_130, %onnx::Conv_131)\n  %/block3/relu/Relu_output_0 = Relu(%/block3/conv3_1_1/Conv_output_0)\n  %/block3/conv3_1_2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block3/relu/Relu_output_0, %onnx::Conv_133, %onnx::Conv_134)\n  %/block3/concat_adjust_3/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/block2_2/relu_1/Relu_output_0, %block3.concat_adjust_3.weight, %block3.concat_adjust_3.bias)\n  %/block3/Add_output_0 = Add(%/block3/conv3_1_2/Conv_output_0, %/block3/concat_adjust_3/Conv_output_0)\n  %/block3/relu_1/Relu_output_0 = Relu(%/block3/Add_output_0)\n  %/block3/conv3_2_1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block3/relu_1/Relu_output_0, %onnx::Conv_136, %onnx::Conv_137)\n  %/block3/relu_2/Relu_output_0 = Relu(%/block3/conv3_2_1/Conv_output_0)\n  %/block3/conv3_2_2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/block3/relu_2/Relu_output_0, %onnx::Conv_139, %onnx::Conv_140)\n  %/block3/Add_1_output_0 = Add(%/block3/conv3_2_2/Conv_output_0, %/block3/relu_1/Relu_output_0)\n  %/block3/relu_3/Relu_output_0 = Relu(%/block3/Add_1_output_0)\n  %/avgpool/GlobalAveragePool_output_0 = GlobalAveragePool(%/block3/relu_3/Relu_output_0)\n  %/Shape_output_0 = Shape(%/avgpool/GlobalAveragePool_output_0)\n  %/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\n  %/Gather_output_0 = Gather[axis = 0](%/Shape_output_0, %/Constant_output_0)\n  %/Unsqueeze_output_0 = Unsqueeze[axes = [0]](%/Gather_output_0)\n  %/Constant_1_output_0 = Constant[value = <Tensor>]()\n  %/Concat_output_0 = Concat[axis = 0](%/Unsqueeze_output_0, %/Constant_1_output_0)\n  %/Reshape_output_0 = Reshape(%/avgpool/GlobalAveragePool_output_0, %/Concat_output_0)\n  %/fc/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/Reshape_output_0, %fc.weight, %fc.bias)\n  %output = Gemm[alpha = 1, beta = 1, transB = 1](%/fc/Gemm_output_0, %out.weight, %out.bias)\n  return %output\n}\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"!pip install onnxruntime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:14:29.564822Z","iopub.execute_input":"2025-03-11T22:14:29.565127Z","iopub.status.idle":"2025-03-11T22:14:35.503085Z","shell.execute_reply.started":"2025-03-11T22:14:29.565090Z","shell.execute_reply":"2025-03-11T22:14:35.502206Z"}},"outputs":[{"name":"stdout","text":"Collecting onnxruntime\n  Downloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\nDownloading onnxruntime-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.0\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"\n\nimport onnxruntime as ort\n\nsession = ort.InferenceSession(\"/kaggle/working/resnet18_v1.onnx\")\ninputs = {session.get_inputs()[0].name: dummy_input.numpy()}\noutputs = session.run(None, inputs)\nprint(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:14:35.504445Z","iopub.execute_input":"2025-03-11T22:14:35.504781Z","iopub.status.idle":"2025-03-11T22:14:35.556509Z","shell.execute_reply.started":"2025-03-11T22:14:35.504754Z","shell.execute_reply":"2025-03-11T22:14:35.555681Z"}},"outputs":[{"name":"stdout","text":"[array([[-0.02527974, -0.05944184,  0.04687503,  0.08315577,  0.00663027,\n        -0.05959833, -0.03492719,  0.05199958,  0.06684899, -0.11986826]],\n      dtype=float32)]\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"\nfrom torchvision import transforms\nfrom PIL import Image\nimport numpy as np\n\n\nimage_path = \"/kaggle/input/example-image/example1.jpg\"  # Path to your 28x28 image\nimage = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n\n# Define preprocessing steps\npreprocess = transforms.Compose([\n    transforms.Resize((28, 28)),  # Resize to 28x28 (if needed)\n    transforms.ToTensor(),         # Convert to tensor\n    transforms.Normalize((0.5,), (0.5,))  # Normalize (if required)\n])\n\n# Preprocess the image\ninput_tensor = preprocess(image)  # Shape: [1, 28, 28]\ninput_tensor = input_tensor.unsqueeze(0)  # Add batch dimension: [1, 1, 28, 28]\n\n# Perform inference\nwith torch.no_grad():\n    output = model(input_tensor)\n\n# Interpret the output\npredicted_class = torch.argmax(output, dim=1).item()\nprint(f\"Predicted class: {predicted_class}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T22:31:39.908728Z","iopub.execute_input":"2025-03-11T22:31:39.909078Z","iopub.status.idle":"2025-03-11T22:31:40.485408Z","shell.execute_reply.started":"2025-03-11T22:31:39.909046Z","shell.execute_reply":"2025-03-11T22:31:40.484573Z"}},"outputs":[{"name":"stdout","text":"Predicted class: 3\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}